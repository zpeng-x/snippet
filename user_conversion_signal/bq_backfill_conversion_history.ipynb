{"cells": [{"cell_type": "code", "execution_count": 4, "metadata": {"execution": {"iopub.execute_input": "2025-09-17T04:15:00.446380Z", "iopub.status.busy": "2025-09-17T04:15:00.445946Z", "iopub.status.idle": "2025-09-17T04:15:00.457377Z", "shell.execute_reply": "2025-09-17T04:15:00.456224Z", "shell.execute_reply.started": "2025-09-17T04:15:00.446337Z"}, "tags": []}, "outputs": [], "source": "import sys\nimport pandas as pd\nimport json\nimport os\nimport logging\nimport numpy as np\nimport datetime\n\n############### Initialize BigQuery Client ###############\n\nfrom google.cloud import bigquery, bigquery_storage\nfrom google.oauth2 import service_account\n\n\nWD = \"/var/lib/mesos/slaves/1773e61b-66cc-4c76-9f4e-6a16e4569303-S6739/frameworks/201205082337-0000000003-0000/executors/thermos-ads-prediction-devel-zhejianp-spark-notebook-0-28b245fb-90b5-4c0c-a70a-445d37a1cd2f/runs/0754985d-601f-4748-a7de-aaf52c448cb5/sandbox/workspace/\"\n# Path to your service account JSON key file\nkey_path = os.path.join(WD, \"twttr/twttr-rev-core-data-prod-d3dac275bdaf.txt\")\n\n# Load credentials\ncredentials = service_account.Credentials.from_service_account_file(\n    key_path,\n    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n)\n\n# Initialize BigQuery client with the service account\nclient = bigquery.Client(\n    credentials=credentials,\n    project=credentials.project_id,  # Or specify your project ID: \"your-project-id\"\n    location=\"US\"  # Match the dataset's location (e.g., US, EU)\n)\n\nbqstorage_client = bigquery_storage.BigQueryReadClient(credentials=credentials)\n########################################################\n\n"}, {"cell_type": "code", "execution_count": 35, "metadata": {"execution": {"iopub.execute_input": "2025-09-19T05:03:44.897864Z", "iopub.status.busy": "2025-09-19T05:03:44.897491Z", "iopub.status.idle": "2025-09-19T05:03:44.902996Z", "shell.execute_reply": "2025-09-19T05:03:44.902178Z", "shell.execute_reply.started": "2025-09-19T05:03:44.897832Z"}, "tags": []}, "outputs": [], "source": "start_date = datetime.date(2025, 9, 18)\nend_date = datetime.date(2025, 9, 18)\n\ndate_list = [\n    (start_date + datetime.timedelta(days=i)).strftime(\"%Y-%m-%d\")\n    for i in range((end_date - start_date).days + 1)\n]\n\n"}, {"cell_type": "code", "execution_count": 36, "metadata": {"execution": {"iopub.execute_input": "2025-09-19T05:03:48.207423Z", "iopub.status.busy": "2025-09-19T05:03:48.207029Z", "iopub.status.idle": "2025-09-19T05:20:14.132092Z", "shell.execute_reply": "2025-09-19T05:20:14.131200Z", "shell.execute_reply.started": "2025-09-19T05:03:48.207378Z"}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Running 2025-09-18, and save to 20250918 \nBigQuery Job ID for 2025-09-18: 019fb8d4-1195-4127-bdbd-51bc1ee55d60\nQuery succeeded for 2025-09-18 and table created: dpa_attributed_conversion_30d_20250918\n"}], "source": "from string import Template\n\nquery_template = Template(\"\"\"\nDECLARE utc_date DATE DEFAULT '${date}';\nCREATE OR REPLACE TABLE `twttr-rev-core-data-prod.dpa.dpa_attributed_conversion_30d_${date_nodash}`\nAS\nWITH ad_impression AS \n( SELECT * FROM ( SELECT impressionData.impressionId AS impressionId, clientInfo.userId64 AS userId64, clientInfo.deviceId AS deviceId, IF(impressionData.dpaData IS NOT NULL, 1, 0) AS isDpa, impressionData.promotedTweetId, impressionData.requestId, impressionData.advertiserId, impressionData.accountId, impressionData.campaignId, impressionData.lineItemId, impressionData.mediaCreativeDetails.mediaId, impressionData.mediaCreativeDetails.creativeId64, impressionData.promotedAppId, impressionData.dpaData.productIds, impressionData.dpaData.productSetId, impressionData.dpaData.productKeys, impressionCallbackEpochTimeMilliSec, ROW_NUMBER() OVER ( PARTITION BY impressionData.impressionId ORDER BY impressionCallbackEpochTimeMilliSec DESC ) AS rn FROM `twttr-rev-core-data-prod.logs.ads_impression_callback_events` WHERE DATE(_PARTITIONTIME) BETWEEN DATE_SUB(utc_date , INTERVAL 30 DAY) AND utc_date AND impressionData.impressionId IS NOT NULL ) WHERE rn = 1 ), \nad_conversion AS ( SELECT impressionId, ANY_VALUE(octOrMact) AS octOrMact, ARRAY_AGG(DISTINCT conversionType IGNORE NULLS) AS uniqueConversionTypes, ANY_VALUE(advertiserAccountId) AS advertiserAccountId, MAX(conversion_time_ms) AS conversion_time_ms, ANY_VALUE(datehour) as datehour FROM ( SELECT COALESCE( engagementCounterKey.dimensions.octDimensions.impressionId, engagementCounterKey.dimensions.mactDimensions.impressionId ) AS impressionId, IF( engagementCounterKey.dimensions.octDimensions.impressionId IS NOT NULL, 'octDimensions', 'mactDimensions' ) AS octOrMact, conversionId.conversionType AS conversionType, COALESCE( processedConversionRecord.mactProcessedConversionRecord.appConversionEvent.conversion_time_ms, lifeTimeValueParameters.attributedInstallEvent.conversion_time_ms ) AS conversion_time_ms, conversionId.advertiserId AS advertiserId, COALESCE( processedConversionRecord.octProcessedConversionRecord.anonymousConversionRecord.advertiserAccountId, processedConversionRecord.mactProcessedConversionRecord.advertiserAccountId ) AS advertiserAccountId, datehour FROM `twttr-bq-ads-attribution-prod.rdu_dataset.attributed_conversion_record` WHERE interactionPrivacyStatus.appTrackingTransparencyStatus = 1 AND conversionId.conversionType IN (2, 3, 4, 6, 7, 12, 13, 32) AND DATE(datehour)= DATE_SUB(utc_date , INTERVAL 1 DAY)) GROUP BY impressionId ), \ndpa_click_data AS ( SELECT engagementEvent.impressionData.impressionId, engagementEvent.impressionData.userId64 AS userId64, engagementEvent.engagementEpochTimeMilliSec AS engagementEpochTimeMilliSec, engagementEvent.engagementDetails.ucEventMetadata.mediaIndex AS mediaIndex, engagementEvent.impressionData.dpaData.productKeys AS productKeys, engagementEvent.engagementType AS engagementType, CASE WHEN engagementEvent.engagementDetails.ucEventMetadata.mediaIndex IS NOT NULL AND ARRAY_LENGTH(engagementEvent.impressionData.dpaData.productKeys) > engagementEvent.engagementDetails.ucEventMetadata.mediaIndex AND engagementEvent.engagementDetails.ucEventMetadata.mediaIndex >= 0 THEN engagementEvent.impressionData.dpaData.productKeys[ OFFSET(engagementEvent.engagementDetails.ucEventMetadata.mediaIndex) ] ELSE NULL END AS clickedProductKey, CASE WHEN engagementEvent.engagementDetails.ucEventMetadata.mediaIndex IS NULL THEN 'media_index_null' WHEN engagementEvent.engagementDetails.ucEventMetadata.mediaIndex < 0 THEN 'media_index_negative' WHEN ARRAY_LENGTH(engagementEvent.impressionData.dpaData.productKeys) <= engagementEvent.engagementDetails.ucEventMetadata.mediaIndex THEN 'mediaIndex_out_of_bounds' ELSE 'product_key_available' END AS status \nFROM `twttr-rev-core-data-prod.logs.ads_spend_event` WHERE DATE(_PARTITIONTIME) BETWEEN DATE(DATE_SUB(utc_date , INTERVAL 30 DAY)) AND DATE(utc_date ) AND engagementEvent.impressionData.dpaData IS NOT NULL AND engagementEvent.engagementType = 42 -- Click \n) \n\nSELECT ad_impression.impressionId, ad_impression.userId64, ad_impression.deviceId, ad_impression.isDpa, ad_impression.promotedTweetId, ad_impression.requestId, ad_impression.advertiserId, ad_impression.accountId, ad_impression.campaignId, ad_impression.lineItemId, ad_impression.mediaId, ad_impression.creativeId64, ad_impression.promotedAppId, ad_impression.productIds, ad_impression.productSetId, ad_impression.impressionCallbackEpochTimeMilliSec, ad_conversion.octOrMact, ad_conversion.uniqueConversionTypes, ad_conversion.conversion_time_ms, dpa_click_data.clickedProductKey, dpa_click_data.engagementType, COALESCE(dpa_click_data.productKeys, ad_impression.productKeys) AS productKeys, dpa_click_data.status, utc_date as _date FROM ad_impression INNER JOIN ad_conversion ON ad_impression.impressionId = ad_conversion.impressionId LEFT JOIN dpa_click_data ON ad_impression.impressionId = dpa_click_data.impressionId\n\n\n\"\"\")\n\nfor date in date_list:\n  date_nodash = datetime.datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n  print(f\"Running {date}, and save to {date_nodash} \")\n  query = query_template.substitute(date=date, date_nodash=date_nodash)\n\n  # Run BQ\n  query_job = client.query(query)\n  job_id = query_job.job_id\n  print(f\"BigQuery Job ID for {date}: {job_id}\")\n\n  query_job.result()  # Blocks until query finishes\n\n  # Check for success\n  if query_job.errors:\n      print(f\"Query failed for {date}: {query_job.errors}\")\n  else:\n      print(f\"Query succeeded for {date} and table created: dpa_attributed_conversion_30d_{date_nodash}\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "pip-py310", "language": "python", "name": "pip-py310"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}, "twitter_notebook": {"markedPDPSafe": false, "notebook_id": "1968110800889057564"}}, "nbformat": 4, "nbformat_minor": 4}